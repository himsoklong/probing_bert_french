{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd95ae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:11:33.657922Z",
     "start_time": "2023-02-09T13:11:33.644901Z"
    }
   },
   "outputs": [],
   "source": [
    "import conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e310efc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:18:19.250200Z",
     "start_time": "2023-02-09T13:18:18.706725Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('datasets/fr_sequoia-ud-train.conllu') as fp:\n",
    "    data = conllu.parse(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "69459e82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:20:54.381837Z",
     "start_time": "2023-02-09T13:20:54.374437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenTree<token={id=8, form=entré}, children=[...]>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[100].to_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd042145",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T07:15:00.642891Z",
     "start_time": "2023-02-10T07:14:59.908664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', 'Tout', 'simplement', '\"', ',', 'a', 'prÃ©cisÃ©', 'Roger', 'Thiriot', ',', '\"', 'parce', 'que', \"l'\", 'histoire', 'du', 'de', 'le', 'travail', 'industriel', 'est', ',', 'ici', ',', 'une', 'longue', 'et', 'vieille', 'histoire', '.']\n",
      "['PUNCT', 'ADV', 'ADV', 'PUNCT', 'PUNCT', 'AUX', 'VERB', 'PROPN', 'PROPN', 'PUNCT', 'PUNCT', 'SCONJ', 'SCONJ', 'DET', 'NOUN', '_', 'ADP', 'DET', 'NOUN', 'ADJ', 'AUX', 'PUNCT', 'ADV', 'PUNCT', 'DET', 'ADJ', 'CCONJ', 'ADJ', 'NOUN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "def load_conllu(filename):\n",
    "    with open(filename) as fp:\n",
    "        data = conllu.parse(fp.read())\n",
    "        sentences = [[token['form'] for token in sentence] for sentence in data]\n",
    "        taggings = [[token['upos'] for token in sentence] for sentence in data]\n",
    "    return sentences, taggings\n",
    "\n",
    "train_sentences, train_taggings = load_conllu('./datasets/fr_sequoia-ud-train.conllu')\n",
    "valid_sentences, valid_taggings = load_conllu('./datasets/fr_sequoia-ud-dev.conllu')\n",
    "test_sentences, test_taggings = load_conllu('./datasets/fr_sequoia-ud-test.conllu')\n",
    "\n",
    "print(train_sentences[10])\n",
    "print(train_taggings[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59147f71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:07.705827Z",
     "start_time": "2023-02-09T13:33:07.701705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2231"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "174c6125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T06:58:07.898135Z",
     "start_time": "2023-02-10T06:58:07.818594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different tags: 17\n",
      "10870 NOUN\n",
      "8043 ADP\n",
      "7430 DET\n",
      "5702 PUNCT\n",
      "4248 VERB\n",
      "3125 ADJ\n",
      "2410 PROPN\n",
      "2083 PRON\n",
      "1889 ADV\n",
      "1623 AUX\n",
      "1360 _\n",
      "1203 CCONJ\n",
      "1183 NUM\n",
      "550 SCONJ\n",
      "128 X\n",
      "15 SYM\n",
      "3 INTJ\n"
     ]
    }
   ],
   "source": [
    "# use a defaultdict to count the number of occurrences of each tag\n",
    "import collections\n",
    "tagset = collections.defaultdict(int)\n",
    "\n",
    "for tagging in train_taggings:\n",
    "    for tag in tagging:\n",
    "        tagset[tag] += 1\n",
    "\n",
    "print('number of different tags:', len(tagset))\n",
    "\n",
    "# print count and tag sorted by decreasing count\n",
    "for tag, count in sorted(tagset.items(), reverse=True, key=lambda x: x[1]):\n",
    "    print(count, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc9c6fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T06:58:23.231475Z",
     "start_time": "2023-02-10T06:58:22.551570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 125\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# compute and show histogram for sentence length\n",
    "plt.hist([len(sentence) for sentence in train_sentences], 20)\n",
    "plt.show()\n",
    "\n",
    "# compute max sentence length\n",
    "print('max length:', max([len(sentence) for sentence in train_sentences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f7c301c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from mangoes.modeling import PretrainedTransformerModelForFeatureExtraction\n",
    "Camembert_model = PretrainedTransformerModelForFeatureExtraction.load(\"camembert-base\", \"camembert-base\", device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20bb28cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = Camembert_model.generate_outputs(\" \".join(valid_sentences[1]), pre_tokenized=False, output_hidden_states=True, output_attentions=False, word_embeddings=True)\n",
    "output['hidden_states'][-1][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5de09a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagsSet = set()\n",
    "for sent in train_taggings:\n",
    "    for tag in sent:\n",
    "        tagsSet.add(tag)\n",
    "tagsList =  list(tagsSet)\n",
    "tag_to_indx = {k: v for v, k in enumerate(tagsList)}\n",
    "indx_to_tag = {v: k for k, v in tag_to_indx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd89f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def encode(data_y):\n",
    "    encoded_y = []\n",
    "    for sent in data_y:\n",
    "        tag_list = []\n",
    "        for tag in sent.split(' '):\n",
    "            tag_list.append(str(tag_to_indx[tag]))\n",
    "\n",
    "        encoded_y.append(\" \".join(tag_list))\n",
    "    return encoded_y\n",
    "\n",
    "train_x = [\" \".join(x) for x in train_sentences]\n",
    "train_y = [\" \".join(x) for x in train_taggings]\n",
    "train_y = encode(train_y)\n",
    "train_data = pd.DataFrame({\"X\": train_x, \"y\": train_y})\n",
    "\n",
    "valid_x = [\" \".join(x) for x in valid_sentences]\n",
    "valid_y = [\" \".join(x) for x in valid_taggings]\n",
    "valid_y = encode(valid_y)\n",
    "valid_data = pd.DataFrame({\"X\": valid_x, \"y\": valid_y})\n",
    "\n",
    "test_x = [\" \".join(x) for x in test_sentences]\n",
    "test_y = [\" \".join(x) for x in test_taggings]\n",
    "test_y = encode(test_y)\n",
    "test_data = pd.DataFrame({\"X\": test_x, \"y\": test_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a28334c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "class PandasDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.data.loc[index, \"X\"]\n",
    "        return {\"X\": sentence, \"y\": self.data.loc[index, \"y\"]}\n",
    "    \n",
    "train_dataloader = DataLoader(PandasDataset(train_data), \n",
    "                              shuffle=True, batch_size=BATCH_SIZE\n",
    ")\n",
    "val_dataloader = DataLoader(PandasDataset(valid_data), \n",
    "                            batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataloader = DataLoader(PandasDataset(test_data), \n",
    "                             batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "742f0a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 59, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch = next(iter(train_dataloader))\n",
    "output = Camembert_model.generate_outputs(example_batch[\"X\"], pre_tokenized=False, output_hidden_states=True, output_attentions=False, word_embeddings=True)\n",
    "output['hidden_states'][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e8c7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cac85be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMPOSTagger(nn.Module):\n",
    "    def __init__(self, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim, \n",
    "                 output_dim, \n",
    "                 n_layers, \n",
    "                 bidirectional, \n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "         \n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            num_layers = n_layers, \n",
    "                            bidirectional = bidirectional,\n",
    "                            dropout = dropout if n_layers > 1 else 0)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, embedded):\n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        #pass embeddings into LSTM\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        \n",
    "        #outputs holds the backward and forward hidden states in the final layer\n",
    "        #hidden and cell are the backward and forward hidden and cell states at the final time-step\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim * n directions]\n",
    "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #we use our outputs to make a prediction of what the tag should be\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        \n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62c0517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 768\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = len(tagsList)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.1\n",
    "TAG_PAD_IDX = tag_to_indx[\"_\"]\n",
    "\n",
    "model = BiLSTMPOSTagger(EMBEDDING_DIM, \n",
    "                        HIDDEN_DIM, \n",
    "                        OUTPUT_DIM, \n",
    "                        N_LAYERS, \n",
    "                        BIDIRECTIONAL, \n",
    "                        DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7044e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
    "        \n",
    "model.apply(init_weights)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a3d39cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,319,185 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3987c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 59, 17])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model(output['hidden_states'][-1])\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "437aed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y, tag_pad_idx):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
    "    return correct.sum() / y[non_pad_elements].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3053c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_Tag(batch_y, max_len):\n",
    "    # if(max_len == None):\n",
    "    #     max_len =  max([len(x.split(' ')) for x in batch_y])\n",
    "    padded_batch = []\n",
    "    for sent in batch_y:\n",
    "        sent_list = sent.split(' ')\n",
    "        sent_list = [int(x) for x in sent_list]\n",
    "        while(len(sent_list)< max_len):\n",
    "            sent_list.append(TAG_PAD_IDX)\n",
    "        padded_batch.append(sent_list)\n",
    "    return padded_batch\n",
    "# padded_batch = pad_Tag(example_batch[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f830b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, pretrained_model, iterator, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        text = batch[\"X\"]\n",
    "        output = pretrained_model.generate_outputs(text, pre_tokenized=False, output_hidden_states=True, output_attentions=False, word_embeddings=True)\n",
    "        embedded = output['hidden_states'][-1]\n",
    "        tags = batch[\"y\"]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #text = [sent len, batch size] \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        predictions = model(embedded)\n",
    "        max_len = predictions.shape[1]\n",
    "        tags = torch.LongTensor(pad_Tag(tags, max_len))\n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "        #tags = [sent len, batch size]\n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "            \n",
    "        #predictions = [sent len * batch size, output dim]\n",
    "        \n",
    "        #tags = [sent len * batch size]\n",
    "        \n",
    "        loss = criterion(predictions, tags)\n",
    "                \n",
    "        acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e000ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, pretrained_model, iterator, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text = batch[\"X\"]\n",
    "            output = pretrained_model.generate_outputs(text, pre_tokenized=False,\n",
    "                                                        output_hidden_states=True, \n",
    "                                                        output_attentions=False, \n",
    "                                                        word_embeddings=True)\n",
    "            embedded = output['hidden_states'][-1]\n",
    "            tags = batch[\"y\"]\n",
    "            \n",
    "            predictions = model(embedded)\n",
    "            \n",
    "            max_len = predictions.shape[1]\n",
    "            tags = torch.LongTensor(pad_Tag(tags, max_len))\n",
    "            \n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "            \n",
    "            loss = criterion(predictions, tags)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57d33cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 9m 54s\n",
      "\tTrain Loss: 1.860 | Train Acc: 38.35%\n",
      "\t Val. Loss: 1.599 |  Val. Acc: 46.22%\n",
      "Epoch: 02 | Epoch Time: 9m 46s\n",
      "\tTrain Loss: 1.521 | Train Acc: 48.34%\n",
      "\t Val. Loss: 1.514 |  Val. Acc: 47.99%\n",
      "Epoch: 03 | Epoch Time: 9m 48s\n",
      "\tTrain Loss: 1.425 | Train Acc: 50.59%\n",
      "\t Val. Loss: 1.451 |  Val. Acc: 49.49%\n",
      "Epoch: 04 | Epoch Time: 10m 30s\n",
      "\tTrain Loss: 1.369 | Train Acc: 52.30%\n",
      "\t Val. Loss: 1.422 |  Val. Acc: 49.57%\n",
      "Epoch: 05 | Epoch Time: 10m 59s\n",
      "\tTrain Loss: 1.323 | Train Acc: 53.37%\n",
      "\t Val. Loss: 1.428 |  Val. Acc: 50.03%\n",
      "Epoch: 06 | Epoch Time: 11m 37s\n",
      "\tTrain Loss: 1.282 | Train Acc: 54.49%\n",
      "\t Val. Loss: 1.403 |  Val. Acc: 50.38%\n",
      "Epoch: 07 | Epoch Time: 10m 44s\n",
      "\tTrain Loss: 1.254 | Train Acc: 55.01%\n",
      "\t Val. Loss: 1.385 |  Val. Acc: 51.00%\n",
      "Epoch: 08 | Epoch Time: 106m 42s\n",
      "\tTrain Loss: 1.209 | Train Acc: 56.65%\n",
      "\t Val. Loss: 1.422 |  Val. Acc: 50.70%\n",
      "Epoch: 09 | Epoch Time: 7m 13s\n",
      "\tTrain Loss: 1.182 | Train Acc: 57.48%\n",
      "\t Val. Loss: 1.389 |  Val. Acc: 50.66%\n",
      "Epoch: 10 | Epoch Time: 9m 26s\n",
      "\tTrain Loss: 1.145 | Train Acc: 58.67%\n",
      "\t Val. Loss: 1.374 |  Val. Acc: 51.40%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, Camembert_model, train_dataloader, optimizer, criterion, TAG_PAD_IDX)\n",
    "    valid_loss, valid_acc = evaluate(model, Camembert_model,val_dataloader, criterion, TAG_PAD_IDX)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37fc1b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.344 |  Test Acc: 52.20%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_dataloader, criterion, TAG_PAD_IDX)\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f81a5a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 7.24kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 625/625 [00:00<00:00, 151kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 996k/996k [00:00<00:00, 1.65MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.96M/1.96M [00:00<00:00, 2.39MB/s]\n",
      "Downloading (…)\"pytorch_model.bin\";: 100%|██████████| 714M/714M [01:48<00:00, 6.59MB/s] \n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "Flaubert_model = PretrainedTransformerModelForFeatureExtraction.load('bert-base-multilingual-cased',\n",
    "                                                                      'bert-base-multilingual-cased', device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b51d635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 8m 6s\n",
      "\tTrain Loss: 0.588 | Train Acc: 82.64%\n",
      "\t Val. Loss: 0.302 |  Val. Acc: 92.57%\n",
      "Epoch: 02 | Epoch Time: 7m 37s\n",
      "\tTrain Loss: 0.199 | Train Acc: 94.72%\n",
      "\t Val. Loss: 0.252 |  Val. Acc: 93.81%\n",
      "Epoch: 03 | Epoch Time: 7m 29s\n",
      "\tTrain Loss: 0.143 | Train Acc: 96.43%\n",
      "\t Val. Loss: 0.224 |  Val. Acc: 94.52%\n",
      "Epoch: 04 | Epoch Time: 8m 29s\n",
      "\tTrain Loss: 0.112 | Train Acc: 97.17%\n",
      "\t Val. Loss: 0.219 |  Val. Acc: 94.83%\n",
      "Epoch: 05 | Epoch Time: 8m 50s\n",
      "\tTrain Loss: 0.088 | Train Acc: 97.78%\n",
      "\t Val. Loss: 0.214 |  Val. Acc: 94.90%\n",
      "Epoch: 06 | Epoch Time: 8m 34s\n",
      "\tTrain Loss: 0.071 | Train Acc: 98.17%\n",
      "\t Val. Loss: 0.224 |  Val. Acc: 94.92%\n",
      "Epoch: 07 | Epoch Time: 264m 56s\n",
      "\tTrain Loss: 0.061 | Train Acc: 98.38%\n",
      "\t Val. Loss: 0.219 |  Val. Acc: 94.93%\n",
      "Epoch: 08 | Epoch Time: 14m 26s\n",
      "\tTrain Loss: 0.049 | Train Acc: 98.66%\n",
      "\t Val. Loss: 0.230 |  Val. Acc: 94.94%\n",
      "Epoch: 09 | Epoch Time: 15m 15s\n",
      "\tTrain Loss: 0.040 | Train Acc: 98.90%\n",
      "\t Val. Loss: 0.232 |  Val. Acc: 95.09%\n",
      "Epoch: 10 | Epoch Time: 60m 46s\n",
      "\tTrain Loss: 0.032 | Train Acc: 99.13%\n",
      "\t Val. Loss: 0.236 |  Val. Acc: 95.07%\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, Flaubert_model, train_dataloader, optimizer, criterion, TAG_PAD_IDX)\n",
    "    valid_loss, valid_acc = evaluate(model, Flaubert_model,val_dataloader, criterion, TAG_PAD_IDX)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3e22136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\experiments\\package-env\\lib\\site-packages\\mangoes\\modeling\\bert_base.py:247: RuntimeWarning: Tokenizer type does not support offset mappings, so word embedding consolidation is not possible\n",
      "  warnings.warn(\"Tokenizer type does not support offset mappings, so word embedding consolidation is not \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 85, 768])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = Flaubert_model.generate_outputs(example_batch[\"X\"], pre_tokenized=False, \n",
    "                                         output_hidden_states=True, output_attentions=False, \n",
    "                                         word_embeddings=True)\n",
    "output['hidden_states'][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "512b83aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Les patients doivent Ãªtre correctement hydratÃ©s avant l' administration d' Aclasta .\",\n",
       " 'Une agrÃ©able surprise qui attendait les enfants dÃ¨s le matin .',\n",
       " 'Affaire des de les piastres',\n",
       " \"Il n' existe pas d' antidote connu pour la bivalirudine , mais son effet disparaÃ®t rapidement ( TÂ½ 35 Ã\\xa0 40 minutes ) .\",\n",
       " \"- Dimanche 1er fÃ©vrier 2004 : Le prÃ©sident Jacques Chirac demande la crÃ©ation d' une commission d' enquÃªte sur les effractions et les pressions dont auraient eu Ã\\xa0 subir les magistrats de Nanterre ayant eu Ã\\xa0 suivre le dossier de l' Affaire des de les emplois fictifs de la mairie de Paris dans lequel est impliquÃ© Alain JuppÃ© .\",\n",
       " 'Ces dÃ©lÃ©guÃ©s remercient le maire pour avoir pris ses responsabilitÃ©s en amÃ©nageant le parking de la Tour du de le Champ .',\n",
       " \"Pour plus d' informations sur votre condition ou votre traitement , veuillez consulter la notice ( Ã©galement comprise dans l' EPAR ) ou contacter votre mÃ©decin ou votre pharmacien .\",\n",
       " \"Il n' existe pas d' antidote connu pour la bivalirudine ;\"]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch[\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4981b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "package-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "9a2af88ebc7c655107da1f32431a352fd851bc95a2516cf9ef54f065ec937c55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
