{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd95ae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:11:33.657922Z",
     "start_time": "2023-02-09T13:11:33.644901Z"
    }
   },
   "outputs": [],
   "source": [
    "import conllu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0c66890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:13:23.866235Z",
     "start_time": "2023-02-09T13:13:23.855712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# global.columns = ID FORM LEMMA UPOS XPOS FEATS HEAD DEPREL DEPS MISC\n",
      "# sent_id = Europar.550_00011\n",
      "# text = cela signifie que leur consommation énergétique, qui représente actuellement 10% de la consommation énergétique moyenne de l'UE, enregistrera une forte augmentation à mesure qu'ils exigeront des commodités élémentaires comme l'eau chaude et, peut-être même, l'air conditionné, des moyens de transport et la modernisation de leurs industries.\n",
      "1\tcela\tcela\tPRON\t_\tNumber=Sing|PronType=Dem\t2\tnsubj\t_\t_\n",
      "2\tsignifie\tsignifier\tVERB\t_\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t0\troot\t_\t_\n",
      "3\tque\tque\tSCONJ\t_\t_\t22\tmark\t_\t_\n",
      "4\tleur\tson\tDET\t_\tNumber=Sing|Poss=Yes\t5\tdet\t_\t_\n",
      "5\tconsommation\tconsommation\tNOUN\t_\tGender=Fem|Number=Sing\t22\tnsubj\t_\t_\n",
      "6\ténergétique\ténergétique\tADJ\t_\tNumber=Sing\t5\tamod\t_\tSpaceAfter=No\n",
      "7\t,\t,\tPUNCT\t_\t_\t5\tpunct\t_\t_\n"
     ]
    }
   ],
   "source": [
    "with open('../Dataset/UD_French-Sequoia/fr_sequoia-ud-test.conllu') as fp:\n",
    "    for line in fp.readlines()[:10]:\n",
    "        print(line, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e310efc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:18:19.250200Z",
     "start_time": "2023-02-09T13:18:18.706725Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../Dataset/UD_French-Sequoia/fr_sequoia-ud-train.conllu') as fp:\n",
    "    data = conllu.parse(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69459e82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:20:54.381837Z",
     "start_time": "2023-02-09T13:20:54.374437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenTree<token={id=8, form=entré}, children=[...]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[100].to_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd042145",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T07:15:00.642891Z",
     "start_time": "2023-02-10T07:14:59.908664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', 'Tout', 'simplement', '\"', ',', 'a', 'précisé', 'Roger', 'Thiriot', ',', '\"', 'parce', 'que', \"l'\", 'histoire', 'du', 'de', 'le', 'travail', 'industriel', 'est', ',', 'ici', ',', 'une', 'longue', 'et', 'vieille', 'histoire', '.']\n",
      "['PUNCT', 'ADV', 'ADV', 'PUNCT', 'PUNCT', 'AUX', 'VERB', 'PROPN', 'PROPN', 'PUNCT', 'PUNCT', 'SCONJ', 'SCONJ', 'DET', 'NOUN', '_', 'ADP', 'DET', 'NOUN', 'ADJ', 'AUX', 'PUNCT', 'ADV', 'PUNCT', 'DET', 'ADJ', 'CCONJ', 'ADJ', 'NOUN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "def load_conllu(filename):\n",
    "    with open(filename) as fp:\n",
    "        data = conllu.parse(fp.read())\n",
    "        sentences = [[token['form'] for token in sentence] for sentence in data]\n",
    "        taggings = [[token['upos'] for token in sentence] for sentence in data]\n",
    "    return sentences, taggings\n",
    "\n",
    "train_sentences, train_taggings = load_conllu('../Dataset/UD_French-Sequoia/fr_sequoia-ud-train.conllu')\n",
    "valid_sentences, valid_taggings = load_conllu('../Dataset/UD_French-Sequoia/fr_sequoia-ud-dev.conllu')\n",
    "test_sentences, test_taggings = load_conllu('../Dataset/UD_French-Sequoia/fr_sequoia-ud-test.conllu')\n",
    "\n",
    "print(train_sentences[10])\n",
    "print(train_taggings[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59147f71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:07.705827Z",
     "start_time": "2023-02-09T13:33:07.701705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14450"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "174c6125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T06:58:07.898135Z",
     "start_time": "2023-02-10T06:58:07.818594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different tags: 17\n",
      "66434 NOUN\n",
      "56470 ADP\n",
      "54148 DET\n",
      "39010 PUNCT\n",
      "28312 VERB\n",
      "25196 PROPN\n",
      "20964 ADJ\n",
      "15697 PRON\n",
      "12801 ADV\n",
      "11465 AUX\n",
      "9689 _\n",
      "9297 CCONJ\n",
      "9242 NUM\n",
      "2601 SCONJ\n",
      "2234 X\n",
      "618 SYM\n",
      "69 INTJ\n"
     ]
    }
   ],
   "source": [
    "# use a defaultdict to count the number of occurrences of each tag\n",
    "import collections\n",
    "tagset = collections.defaultdict(int)\n",
    "\n",
    "for tagging in train_taggings:\n",
    "    for tag in tagging:\n",
    "        tagset[tag] += 1\n",
    "\n",
    "print('number of different tags:', len(tagset))\n",
    "\n",
    "# print count and tag sorted by decreasing count\n",
    "for tag, count in sorted(tagset.items(), reverse=True, key=lambda x: x[1]):\n",
    "    print(count, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7cc9c6fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T06:58:23.231475Z",
     "start_time": "2023-02-10T06:58:22.551570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 400\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# compute and show histogram for sentence length\n",
    "plt.hist([len(sentence) for sentence in train_sentences], 20)\n",
    "plt.show()\n",
    "\n",
    "# compute max sentence length\n",
    "print('max length:', max([len(sentence) for sentence in train_sentences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1eec6dd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T06:59:04.983470Z",
     "start_time": "2023-02-10T06:59:04.725977Z"
    }
   },
   "outputs": [],
   "source": [
    "# import relevant classes for pretrained tokenizer and model\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1d6d419",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T07:04:41.237638Z",
     "start_time": "2023-02-10T07:04:22.622363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a9f763fb3e4563aff838654a7e4f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/811k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93d81869ece43ce83c650d4fbc38c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2daaf93f2684ebab058b97de763875e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import CamembertModel, CamembertTokenizer\n",
    "\n",
    "# You can replace \"camembert-base\" with any other model from the table, e.g. \"camembert/camembert-large\".\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "camembert = CamembertModel.from_pretrained(\"camembert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7b150b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T07:05:55.057686Z",
     "start_time": "2023-02-10T07:05:55.045095Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁cela',\n",
       " '▁signifie',\n",
       " '▁que',\n",
       " '▁leur',\n",
       " '▁consommation',\n",
       " '▁énergétique',\n",
       " ',',\n",
       " '▁qui',\n",
       " '▁représente',\n",
       " '▁actuellement',\n",
       " '▁10%',\n",
       " '▁de',\n",
       " '▁la',\n",
       " '▁consommation',\n",
       " '▁énergétique',\n",
       " '▁moyenne',\n",
       " '▁de',\n",
       " '▁l',\n",
       " \"'\",\n",
       " 'UE',\n",
       " ',',\n",
       " '▁enregistrer',\n",
       " 'a',\n",
       " '▁une',\n",
       " '▁forte',\n",
       " '▁augmentation',\n",
       " '▁à',\n",
       " '▁mesure',\n",
       " '▁qu',\n",
       " \"'\",\n",
       " 'ils',\n",
       " '▁exiger',\n",
       " 'ont',\n",
       " '▁des',\n",
       " '▁commodités',\n",
       " '▁élémentaires',\n",
       " '▁comme',\n",
       " '▁l',\n",
       " \"'\",\n",
       " 'eau',\n",
       " '▁chaude',\n",
       " '▁et',\n",
       " ',',\n",
       " '▁peut',\n",
       " '-',\n",
       " 'être',\n",
       " '▁même',\n",
       " ',',\n",
       " '▁l',\n",
       " \"'\",\n",
       " 'air',\n",
       " '▁conditionné',\n",
       " ',',\n",
       " '▁des',\n",
       " '▁moyens',\n",
       " '▁de',\n",
       " '▁transport',\n",
       " '▁et',\n",
       " '▁la',\n",
       " '▁modernisation',\n",
       " '▁de',\n",
       " '▁leurs',\n",
       " '▁industries',\n",
       " '.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"cela signifie que leur consommation énergétique, qui représente actuellement 10% de la consommation énergétique moyenne de l'UE, enregistrera une forte augmentation à mesure qu'ils exigeront des commodités élémentaires comme l'eau chaude et, peut-être même, l'air conditionné, des moyens de transport et la modernisation de leurs industries.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee63c68b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T07:15:40.246111Z",
     "start_time": "2023-02-10T07:15:40.003496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁L', \"'\", '▁équipe', '▁B', '▁', ',', '▁chez', '▁les', '▁seniors', '▁', ',', '▁évoluer', 'a', '▁à', '▁partir', '▁de', '▁15', '▁h', '▁', ',', '▁sur', '▁la', '▁pelouse', '▁du', '▁de', '▁le', '▁terrain', '▁d', \"'\", '▁honneur', '▁', ',', '▁face', '▁à', '▁la', '▁formation', '▁de', '▁La', 'neu', 'ville', '▁', '.']\n",
      "['<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def align_tokenizations(sentences, taggings):\n",
    "    bert_tokenized_sentences = []\n",
    "    aligned_taggings = []\n",
    "\n",
    "    for sentence, tagging in zip(sentences, taggings):\n",
    "        # first generate BERT-tokenization\n",
    "        bert_tokenized_sentence = tokenizer.tokenize(' '.join(sentence))\n",
    "\n",
    "        aligned_tagging = []\n",
    "        current_word = ''\n",
    "        index = 0 # index of current word in sentence and tagging\n",
    "        for token in bert_tokenized_sentence:\n",
    "            current_word += re.sub(r'^##', '', token) # recompose word with subtoken\n",
    "            sentence[index] = sentence[index].replace('\\xad', '') # fix bug in data\n",
    "\n",
    "            # note that some word factors correspond to unknown words in BERT\n",
    "#             assert token == '[UNK]' or sentence[index].startswith(current_word)\n",
    "\n",
    "            if token == '[UNK]' or sentence[index] == current_word: # if we completed a word\n",
    "                current_word = ''\n",
    "                aligned_tagging.append(tagging[index])\n",
    "                index += 1\n",
    "            else: # otherwise insert padding\n",
    "                aligned_tagging.append('<pad>')\n",
    "\n",
    "        assert len(bert_tokenized_sentence) == len(aligned_tagging)\n",
    "\n",
    "        bert_tokenized_sentences.append(bert_tokenized_sentence)\n",
    "        aligned_taggings.append(aligned_tagging)\n",
    "\n",
    "    return bert_tokenized_sentences, aligned_taggings\n",
    "\n",
    "train_bert_tokenized_sentences, train_aligned_taggings = align_tokenizations(train_sentences, train_taggings)\n",
    "valid_bert_tokenized_sentences, valid_aligned_taggings = align_tokenizations(valid_sentences, valid_taggings)\n",
    "test_bert_tokenized_sentences, test_aligned_taggings = align_tokenizations(test_sentences, test_taggings)\n",
    "\n",
    "print(train_bert_tokenized_sentences[42])\n",
    "print(train_aligned_taggings[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a57587c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T07:28:35.316366Z",
     "start_time": "2023-02-10T07:28:35.145829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    3,    71,    11,   815,   261,    21,     7,   222,    19,  8383,\n",
      "           21,     7,  5120,    55,    15,   350,     8,   338,   616,    21,\n",
      "            7,    32,    13, 12585,    25,     8,    16,   992,    18,    11,\n",
      "         8515,    21,     7,   461,    15,    13,   513,     8,    61, 23921,\n",
      "          998,    21,     9,     3])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "num labels: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# device = torch.device('gpu' if torch.cuda.is_available else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "import collections\n",
    "\n",
    "label_vocab = collections.defaultdict(lambda: len(label_vocab))\n",
    "label_vocab['<pad>'] = 0\n",
    "\n",
    "def convert_to_ids(sentences, taggings):\n",
    "    sentences_ids = []\n",
    "    taggings_ids = []\n",
    "    for sentence, tagging in zip(sentences, taggings):\n",
    "        sentence_tensor = torch.tensor(tokenizer.convert_tokens_to_ids(['[CLS]'] + sentence + ['SEP'])).long()\n",
    "        tagging_tensor = torch.tensor([0] + [label_vocab[tag] for tag in tagging] + [0]).long()\n",
    "\n",
    "        sentences_ids.append(sentence_tensor.to(device))\n",
    "        taggings_ids.append(tagging_tensor.to(device))\n",
    "    return sentences_ids, taggings_ids\n",
    "\n",
    "train_sentences_ids, train_taggings_ids = convert_to_ids(train_bert_tokenized_sentences, train_aligned_taggings)\n",
    "valid_sentences_ids, valid_taggings_ids = convert_to_ids(valid_bert_tokenized_sentences, valid_aligned_taggings)\n",
    "test_sentences_ids, test_taggings_ids = convert_to_ids(test_bert_tokenized_sentences, test_aligned_taggings)\n",
    "\n",
    "print(train_sentences_ids[42])\n",
    "print(train_taggings_ids[42])\n",
    "print('num labels:', len(label_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18404ad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T07:29:10.991794Z",
     "start_time": "2023-02-10T07:29:10.983887Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PosTaggingDataset(Dataset):\n",
    "    def __init__(self, sentences, taggings):\n",
    "        assert len(sentences) == len(taggings)\n",
    "        self.sentences = sentences\n",
    "        self.taggings = taggings\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.sentences[i], self.taggings[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5a96f47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T07:29:51.838415Z",
     "start_time": "2023-02-10T07:29:51.827057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(items):\n",
    "    max_len = max(len(item[0]) for item in items)\n",
    "\n",
    "    sentences = torch.zeros((len(items), max_len), device=items[0][0].device).long().to(device)\n",
    "    taggings = torch.zeros((len(items), max_len)).long().to(device)\n",
    "\n",
    "    for i, (sentence, tagging) in enumerate(items):\n",
    "        sentences[i][0:len(sentence)] = sentence\n",
    "        taggings[i][0:len(tagging)] = tagging\n",
    "\n",
    "    return sentences, taggings\n",
    "\n",
    "\n",
    "x, y = collate_fn([[torch.tensor([1, 2, 3]), torch.tensor([4, 5, 6])], [torch.tensor([1, 2]), torch.tensor([3, 4])]])\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c7290e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T07:30:04.530430Z",
     "start_time": "2023-02-10T07:30:04.524607Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(PosTaggingDataset(train_sentences_ids, train_taggings_ids), batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "valid_loader = DataLoader(PosTaggingDataset(valid_sentences_ids, valid_taggings_ids), batch_size=batch_size, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(PosTaggingDataset(test_sentences_ids, test_taggings_ids), batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25e2f781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T07:30:46.103504Z",
     "start_time": "2023-02-10T07:30:46.004959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, embed_size=128, hidden_size=128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(tokenizer.vocab_size, embed_size, padding_idx=tokenizer.pad_token_id)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.decision = nn.Linear(1 * 2 * hidden_size, num_labels) # size output by GRU is number of layers * number of directions * hidden size\n",
    "        self.to(device)\n",
    "  \n",
    "    def forward(self, sentences):\n",
    "        embed_rep = self.embedding(sentences)\n",
    "        word_rep, sentence_rep = self.rnn(embed_rep)\n",
    "        return self.decision(F.dropout(F.gelu(word_rep), 0.3))\n",
    "\n",
    "# check that model works on an arbitrary batch that contains two sentences of length 3\n",
    "rnn_model = RNNClassifier(len(label_vocab))\n",
    "with torch.no_grad():\n",
    "    y = rnn_model(torch.tensor([[0, 1, 2], [3, 4, 5]]).to(device))\n",
    "\n",
    "# the expected shape is (batch size, max sentence length, number of labels)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0d2181b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T07:35:06.596886Z",
     "start_time": "2023-02-10T07:35:06.588572Z"
    }
   },
   "outputs": [],
   "source": [
    "def perf(model, loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval() # do not apply training-specific steps such as dropout\n",
    "    total_loss = correct = num_loss = num_perf = 0\n",
    "    for x, y in loader:\n",
    "        with torch.no_grad(): # no need to store computation graph for gradients\n",
    "          # perform inference and compute loss\n",
    "            y_scores = model(x)\n",
    "            loss = criterion(y_scores.view(-1, len(label_vocab)), y.view(-1)) # requires tensors of shape (num-instances, num-labels) and (num-instances)\n",
    "\n",
    "            # gather loss statistics\n",
    "            total_loss += loss.item()\n",
    "            num_loss += 1\n",
    "\n",
    "            # gather accuracy statistics\n",
    "            y_pred = torch.max(y_scores, 2)[1] # compute highest-scoring tag\n",
    "            mask = (y != 0) # ignore <pad> tags\n",
    "            correct += torch.sum((y_pred == y) * mask) # compute number of correct predictions\n",
    "            num_perf += torch.sum(mask).item()\n",
    "            print(num_perf)\n",
    "    return total_loss / num_loss, correct.item() / num_perf\n",
    "\n",
    "# without training, accuracy should be a bit less than 2% (chance of getting a label correct)\n",
    "# perf(rnn_model, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b611ac5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T07:35:52.987177Z",
     "start_time": "2023-02-10T07:35:52.976956Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def fit(model, epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = num = 0\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad() # start accumulating gradients\n",
    "            y_scores = model(x)\n",
    "            loss = criterion(y_scores.view(-1, len(label_vocab)), y.view(-1))\n",
    "            loss.backward() # compute gradients though computation graph\n",
    "            optimizer.step() # modify model parameters\n",
    "            total_loss += loss.item()\n",
    "            num += 1\n",
    "    print(1 + epoch, total_loss / num, *perf(model, valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "baef1b90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T07:36:40.961615Z",
     "start_time": "2023-02-10T07:36:22.223787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m rnn_model \u001b[38;5;241m=\u001b[39m RNNClassifier(\u001b[38;5;28mlen\u001b[39m(label_vocab))\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     16\u001b[0m         num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m epoch, total_loss \u001b[38;5;241m/\u001b[39m num, \u001b[38;5;241m*\u001b[39m\u001b[43mperf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36mperf\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m     19\u001b[0m         num_perf \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(mask)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28mprint\u001b[39m(num_perf)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m num_loss, \u001b[43mcorrect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_perf\u001b[49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "rnn_model = RNNClassifier(len(label_vocab))\n",
    "fit(rnn_model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b7d03e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T07:53:12.040615Z",
     "start_time": "2023-02-10T07:53:11.709744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "class LinearProbeRandom(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(tokenizer.vocab_size, 768)\n",
    "        self.probe = nn.Linear(768, num_labels)\n",
    "        self.to(device)\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.probe.parameters()\n",
    "  \n",
    "    def forward(self, sentences):\n",
    "        with torch.no_grad(): # embeddings are not trained\n",
    "            word_rep = self.embedding(sentences)\n",
    "        return self.probe(word_rep)\n",
    "\n",
    "# the model should return a tensor of shape (batch size, sequence length, number of labels)\n",
    "random_model = LinearProbeRandom(len(label_vocab))\n",
    "with torch.no_grad():\n",
    "    y = random_model(torch.tensor([[0, 1, 2], [3, 4, 5]]).to(device))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fb304808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T07:53:25.395962Z",
     "start_time": "2023-02-10T07:53:24.389530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m random_model \u001b[38;5;241m=\u001b[39m LinearProbeRandom(\u001b[38;5;28mlen\u001b[39m(label_vocab))\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     16\u001b[0m         num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m epoch, total_loss \u001b[38;5;241m/\u001b[39m num, \u001b[38;5;241m*\u001b[39m\u001b[43mperf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36mperf\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m     19\u001b[0m         num_perf \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(mask)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28mprint\u001b[39m(num_perf)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m num_loss, \u001b[43mcorrect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_perf\u001b[49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "random_model = LinearProbeRandom(len(label_vocab))\n",
    "fit(random_model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "164f417a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T07:56:45.821147Z",
     "start_time": "2023-02-10T07:56:44.659766Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "class LinearProbeBert(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        self.camembert = CamembertModel.from_pretrained(\"camembert-base\")\n",
    "        self.probe = nn.Linear(self.camembert.config.hidden_size, num_labels)\n",
    "        self.to(device)\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.probe.parameters()\n",
    "  \n",
    "    def forward(self, sentences):\n",
    "        with torch.no_grad(): # no training of BERT parameters\n",
    "            word_rep, sentence_rep = self.camembert(sentences, return_dict=False)\n",
    "        return self.probe(word_rep)\n",
    "\n",
    "# the model should return a tensor of shape (batch size, sequence length, number of labels)\n",
    "bert_model = LinearProbeBert(len(label_vocab))\n",
    "y = bert_model(torch.tensor([[0, 1, 2], [3, 4, 5]]).to(device))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c9872e15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T08:08:40.709881Z",
     "start_time": "2023-02-10T07:56:57.898212Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m LinearProbeBert(\u001b[38;5;28mlen\u001b[39m(label_vocab))\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbert_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     16\u001b[0m         num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m epoch, total_loss \u001b[38;5;241m/\u001b[39m num, \u001b[38;5;241m*\u001b[39m\u001b[43mperf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36mperf\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m     19\u001b[0m         num_perf \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(mask)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28mprint\u001b[39m(num_perf)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m num_loss, \u001b[43mcorrect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_perf\u001b[49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "bert_model = LinearProbeBert(len(label_vocab))\n",
    "fit(bert_model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db25f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RNN representation (supervised)', *perf(rnn_model, test_loader))\n",
    "print('RANDOM representation (unsupervised)', *perf(random_model, test_loader))\n",
    "print('BERT representation (unsupervised)', *perf(bert_model, test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LR",
   "language": "python",
   "name": "lr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
